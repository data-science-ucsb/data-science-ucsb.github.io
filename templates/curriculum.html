{% extends "base.html" %}

{% block extra_head %}
    <style>
        table {
            border-collapse: collapse; /* This ensures straight lines */
            width: 100%; /* Optional: Adjusts the width of the table */
        }
        th, td {
            border: 1px solid black; /* Sets the border style for table headers and cells */
            text-align: left; /* Aligns text to the left, optional */
            padding: 8px; /* Adds padding inside cells, optional */
            font-size: smaller;
        }
    </style>
{% endblock extra_head %}

{% block content %}

  <p>
    <table>
        <tr>
            <th>Date</th>
            <th>Summary</th>
            <th>Links</th>
        </tr>
        <tr>
            <td>1/12</td>
            <td>Welcome, Review of Transformers, Reproduce GPT-2</td>
            <td>
              <p> <a href="https://www.lesswrong.com/s/PKKsrXtuptWzaKCjr/p/AHhCrJ2KpTjsCSwbt">What is AI alignment?</a> </p>
              <p> <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a> </p>
              <p> <a href="https://www.youtube.com/watch?v=dsjUDacBw8o&list=PL7m7hLIqA0hoIUPhC26ASCVs_VrqcDpAz&index=2">GPT-2 Walkthrough</a> + <a href="https://colab.research.google.com/github/neelnanda-io/Easy-Transformer/blob/clean-transformer-demo/Clean_Transformer_Demo_Template.ipynb">starter code</a></p>
            </td>
        </tr>
        <tr>
            <td>1/19</td>
            <td>Reproduce GPT-2</td>
            <td>
              <p> <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a> </p>
              <p> <a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a> </p>
              <p> <a href="https://www.youtube.com/watch?v=dsjUDacBw8o&list=PL7m7hLIqA0hoIUPhC26ASCVs_VrqcDpAz&index=2">GPT-2 Walkthrough</a> + <a href="https://colab.research.google.com/github/neelnanda-io/Easy-Transformer/blob/clean-transformer-demo/Clean_Transformer_Demo_Template.ipynb">starter code</a></p>
              <p> Learn about <a href="https://einops.rocks/">einops</a>! </p>
            </td>
        </tr>
        <tr>
            <td>1/26</td>
            <td>Introduction to Interpretability</td>
            <td>
              <p> <a href="https://distill.pub/2020/circuits/zoom-in/">Zoom In: An Introduction to Circuits</a> + <a href="https://tanaybiradar.com/blog/notes-on-zoom-in-circuits/">my notes</a> </p>
              <p> <a href="https://transformer-circuits.pub/2021/framework/index.html"> A Mathematical Framework for Transformer Circuits </a> + <a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=aGu9fP1EG3hiVdq169cMOJId">Glossary of Terms</a> + <a href="https://transformer-circuits.pub/2021/exercises/index.html#solutions">self-test</a> + <a href="https://www.youtube.com/watch?v=KV5gbOmHbjU">Neel Nanda's walkthrough</a> </p>
              <p> <a href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html"> In-context Learning and Induction Heads </a> </p>
              <p> Tip: Read these in order. These papers are non-trivial, so spend most of your time on the first two, then just skim the last. </p>
            </td>
        </tr>
    </table>
  </p>

  Some other links and tools that might help you as we progress:
  <ul>
      <li> Meta
        <ul>
          <li> <a href="https://www.talk2arxiv.org/pdf/1706.03762.pdf">Talk2Arxiv (GPT for understanding papers)</a> </li>
        </ul>
      </li>

      <li> Deep Learning Refresher
        <ul>
          <li> <a href="https://edisonzhang.me/Notes/F23/CMPSC-190I/CMPSC-190I-Index">Edison Zhang's CS190I Notes</a> </li>
        </ul>
      </li>

      <li> Transformers
        <ul>
          <li><a href="https://e2eml.school/transformers.html">Transformers from Scratch</a></li>
        </ul>
      </li>

      <li> Mechanistic Interpretability
        <ul>
          <li><a href="https://www.neelnanda.io/mechanistic-interpretability/getting-started">Getting Started in MI</a></li>
          <li><a href="https://www.neelnanda.io/mechanistic-interpretability/favourite-papers">Neel Nanda's List of Papers</a> - includes how to approach each one</li>
          <li><a href="https://www.alignmentforum.org/s/yivyHaCAmMJ3CqSyj/p/XNjRwEX9kxbpzWFWd">200 Concrete Open Problems in MI</a> </li>
        </ul>
      </li>

      <li> Other AI Safety/Alignment Programs + Courses
        <ul>
          <li><a href="https://course.aisafetyfundamentals.com/alignment">AI Alignment Course (MAIA)</a></li>
          <li><a href="https://haist.ai/tech-papers">HAIST Tech Papers</a></li>
          <li><a href="https://docs.google.com/document/d/1NX0DlZRzD3NP7tBeLjMh76w7-w2s8SxV3wj0P7EYpKY/edit">STS 10SI</a></li>
        </ul>
      </li>
  </ul>

{% endblock content %}
